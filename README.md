# Big Models, Small Tweaks: Exploring the LoRA Way of Fine-Tuning
## Exploring-LoRA
The Idea Behind Parameter Efficient Fine-Tuning and Analyzing LoRA through its Implementation on an MLP

Research paper reference: <br>
**LoRA: Low-Rank Adaptation of Large Language Models** <br>
*Edward J. Hu\*, Yelong Shen\*, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen* <br>
Paper: https://arxiv.org/abs/2106.09685 <br>
Video explainer: https://www.youtube.com/watch?v=DhRoTONcyZE <br>

Blog reference:
1. **Exploring LoRA â€” Part 1: The Idea Behind Parameter Efficient Fine-Tuning and LoRA**: https://medium.com/inspiredbrilliance/exploring-lora-part-1-the-idea-behind-parameter-efficient-fine-tuning-and-lora-ec469d176c26
2. **Exploring LoRA - Part 2: Analyzing LoRA through its Implementation on an MLP**: https://medium.com/inspiredbrilliance/exploring-lora-part-2-analyzing-lora-through-its-implementation-on-an-mlp-fbc386036f6f

